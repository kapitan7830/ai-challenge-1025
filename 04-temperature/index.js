import { Telegraf } from 'telegraf';
import OpenAI from 'openai';
import dotenv from 'dotenv';

dotenv.config();

const bot = new Telegraf(process.env.TELEGRAM_BOT_TOKEN);
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const TEMPERATURES = [0, 0.7, 1.2];

const WELCOME_MESSAGE = `ðŸŒ¡ï¸ Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Temperature Ð´Ð»Ñ OpenAI

Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð»ÑŽÐ±Ð¾Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð¸ Ð±Ð¾Ñ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚ Ð½Ð° Ð½ÐµÐ³Ð¾ 3 Ñ€Ð°Ð·Ð° Ñ Ñ€Ð°Ð·Ð½Ñ‹Ð¼Ð¸ Ñ‚ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°Ð¼Ð¸ (0, 0.7, 1.2).

Ð­Ñ‚Ð¾ Ð¿Ð¾Ð·Ð²Ð¾Ð»Ð¸Ñ‚ Ð½Ð°Ð³Ð»ÑÐ´Ð½Ð¾ ÑƒÐ²Ð¸Ð´ÐµÑ‚ÑŒ Ñ€Ð°Ð·Ð½Ð¸Ñ†Ñƒ:
â„ï¸ Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° 0 - Ð´ÐµÑ‚ÐµÑ€Ð¼Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ, Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·ÑƒÐµÐ¼Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹
ðŸŒ¤ï¸ Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° 0.7 - ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼
ðŸ”¥ Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° 1.2 - ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ, Ñ€Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹

ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð½Ð°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¸ ÑÑ€Ð°Ð²Ð½Ð¸Ñ‚Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹!`;

bot.start(async (ctx) => {
  await ctx.reply(WELCOME_MESSAGE);
});

bot.help(async (ctx) => {
  await ctx.reply(WELCOME_MESSAGE);
});

async function answerQuestion(question, temperature) {
  const timeoutPromise = new Promise((_, reject) => {
    setTimeout(() => reject(new Error('Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð¿Ñ€ÐµÐ²Ñ‹ÑÐ¸Ð» Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð² 10 ÑÐµÐºÑƒÐ½Ð´')), 10000);
  });

  const apiPromise = openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [
      {
        role: 'user',
        content: question,
      },
    ],
    temperature: temperature,
  });

  const completion = await Promise.race([apiPromise, timeoutPromise]);

  return {
    answer: completion.choices[0].message.content,
    usage: completion.usage,
  };
}

bot.on('text', async (ctx) => {
  const question = ctx.message.text;
  
  // Skip if it's a command
  if (question.startsWith('/')) {
    return;
  }
  
  try {
    await ctx.sendChatAction('typing');
    
    console.log('\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
    console.log(`â“ Question: ${question}`);
    console.log(`ðŸ‘¤ User: ${ctx.from.username || ctx.from.id}`);
    
    await ctx.reply('â³ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ñ Ñ‚ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°Ð¼Ð¸ 0, 0.7 Ð¸ 1.2...');
    
    // Get answers with different temperatures
    for (const temp of TEMPERATURES) {
      await ctx.sendChatAction('typing');
      
      console.log(`\nðŸŒ¡ï¸  Answering with temperature: ${temp}`);
      
      const tempLabel = temp === 0 ? 'â„ï¸' : temp === 0.7 ? 'ðŸŒ¤ï¸' : 'ðŸ”¥';
      
      try {
        const { answer, usage } = await answerQuestion(question, temp);
        
        console.log(`ðŸ“Š Tokens: prompt=${usage.prompt_tokens}, completion=${usage.completion_tokens}, total=${usage.total_tokens}`);
        console.log(`ðŸ’¬ Answer preview: ${answer.substring(0, 100)}...`);
        
        await ctx.reply(
          `${tempLabel} Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° ${temp}:\n\n${answer}`
        );
      } catch (error) {
        console.error(`âŒ Error with temperature ${temp}:`, error.message);
        await ctx.reply(
          `${tempLabel} Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° ${temp}:\n\nâŒ ÐžÑˆÐ¸Ð±ÐºÐ°: ${error.message}`
        );
      }
      
      // Small delay for better UX
      await new Promise(resolve => setTimeout(resolve, 500));
    }
    
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n');
    
    await ctx.reply('\nâœ… Ð“Ð¾Ñ‚Ð¾Ð²Ð¾! Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ.');
    
  } catch (error) {
    console.error('Error:', error);
    await ctx.reply('ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ðµ Ñ€Ð°Ð·.');
  }
});

bot.launch();

console.log('ðŸŒ¡ï¸ Temperature Demo Bot is running...');

// Enable graceful stop
process.once('SIGINT', () => bot.stop('SIGINT'));
process.once('SIGTERM', () => bot.stop('SIGTERM'));
