import OpenAI from 'openai';
import dotenv from 'dotenv';
import { retryHandler } from './RetryHandler.js';

dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

/**
 * –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI API
 */
export class TokenCounter {
  /**
   * –¢–æ—á–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ —á–µ—Ä–µ–∑ OpenAI API —Å rate limiting
   * @param {string} text - –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞
   * @returns {Promise<number>} - –¢–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
   */
  static async countTokens(text) {
    if (!text) return 0;
    
    try {
      const response = await retryHandler.executeOpenAIRequest(
        () => openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [{ role: 'user', content: text }],
          max_tokens: 1,
        }),
        'gpt-3.5-turbo',
        this.estimate(text)
      );
      
      return response.usage.prompt_tokens;
    } catch (error) {
      console.warn('–û—à–∏–±–∫–∞ —Ç–æ—á–Ω–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É:', error.message);
      return this.estimate(text);
    }
  }

  /**
   * –ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
   * @param {string} text - –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞
   * @returns {number} - –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
   */
  static estimate(text) {
    if (!text) return 0;
    
    // –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: ~2.5 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω
    // –î–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ: ~4 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    const CHARS_PER_TOKEN = 2.5;
    
    return Math.ceil(text.length / CHARS_PER_TOKEN);
  }

  /**
   * –ü—Ä–æ–≤–µ—Ä–∫–∞, –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏ —Ç–µ–∫—Å—Ç –ª–∏–º–∏—Ç
   * @param {string} text - –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
   * @param {number} maxTokens - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
   * @returns {boolean}
   */
  static exceedsLimit(text, maxTokens) {
    return this.estimate(text) > maxTokens;
  }

  /**
   * –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤
   * @param {Object} usage - –û–±—ä–µ–∫—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–∫–µ–Ω–∞—Ö
   * @returns {string}
   */
  static formatUsage(usage) {
    const { prompt_tokens, completion_tokens, total_tokens } = usage;
    return `üìä –í—Ö–æ–¥: ${prompt_tokens} | –í—ã—Ö–æ–¥: ${completion_tokens} | –í—Å–µ–≥–æ: ${total_tokens}`;
  }

  /**
   * –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø—Ä–∏–º–µ—Ä–Ω—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å (–¥–ª—è —Å–ø—Ä–∞–≤–∫–∏)
   * GPT-4: ~$0.03 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤ –≤—Ö–æ–¥–∞, ~$0.06 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤ –≤—ã—Ö–æ–¥–∞
   * GPT-3.5-turbo: ~$0.0015 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤ –≤—Ö–æ–¥–∞, ~$0.002 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤ –≤—ã—Ö–æ–¥–∞
   * GPT-4o: ~$0.005 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤ –≤—Ö–æ–¥–∞, ~$0.015 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤ –≤—ã—Ö–æ–¥–∞
   * GPT-4o-mini: ~$0.00015 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤ –≤—Ö–æ–¥–∞, ~$0.0006 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤ –≤—ã—Ö–æ–¥–∞
   */
  static estimateCost(usage, model = 'gpt-3.5-turbo') {
    const costs = {
      'gpt-4': { input: 0.03, output: 0.06 },
      'gpt-3.5-turbo': { input: 0.0015, output: 0.002 },
      'gpt-4o': { input: 0.005, output: 0.015 },
      'gpt-4o-mini': { input: 0.00015, output: 0.0006 },
    };
    
    const cost = costs[model] || costs['gpt-3.5-turbo'];
    const inputCost = (usage.prompt_tokens / 1000) * cost.input;
    const outputCost = (usage.completion_tokens / 1000) * cost.output;
    
    return (inputCost + outputCost).toFixed(4);
  }
}

