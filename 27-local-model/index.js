import { Telegraf } from 'telegraf';
import OpenAI from 'openai';
import dotenv from 'dotenv';

dotenv.config();

const bot = new Telegraf(process.env.TELEGRAM_BOT_TOKEN);
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Store conversation history per user
const conversations = new Map();

// Logging helper
function log(message, data = '') {
  const timestamp = new Date().toISOString();
  console.log(`[${timestamp}] ${message}`, data);
}

// Agent for OpenAI
async function getOpenAIResponse(messages) {
  log('üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ OpenAI...');
  const startTime = Date.now();
  
  const completion = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: messages,
  });
  
  const duration = Date.now() - startTime;
  log(`‚úÖ OpenAI –æ—Ç–≤–µ—Ç–∏–ª –∑–∞ ${duration}ms`);
  
  return completion.choices[0].message.content;
}

// Agent for Ollama
async function getOllamaResponse(messages) {
  log('üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Ollama...');
  const startTime = Date.now();
  
  const response = await fetch('http://localhost:11434/api/chat', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'llama3.2:3b',
      messages: messages,
      stream: false,
    }),
  });

  if (!response.ok) {
    throw new Error(`Ollama API error: ${response.status}`);
  }

  const data = await response.json();
  const duration = Date.now() - startTime;
  log(`‚úÖ Ollama –æ—Ç–≤–µ—Ç–∏–ª –∑–∞ ${duration}ms`);
  
  return data.message.content;
}

bot.start((ctx) => {
  log(`üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ${ctx.from.id} (@${ctx.from.username || 'unknown'}) –∑–∞–ø—É—Å—Ç–∏–ª –±–æ—Ç–∞`);
  ctx.reply('Hey! Send me any message and I\'ll forward it to both OpenAI and Ollama.');
});

bot.help((ctx) => {
  log(`‚ùì –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ${ctx.from.id} –∑–∞–ø—Ä–æ—Å–∏–ª –ø–æ–º–æ—â—å`);
  ctx.reply('Send me any text and I\'ll get responses from both OpenAI and Ollama.\nUse /clear to reset conversation history.');
});

bot.command('clear', (ctx) => {
  const userId = ctx.from.id;
  const historyLength = conversations.get(userId)?.length || 0;
  conversations.delete(userId);
  log(`üóëÔ∏è  –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ${userId} –æ—á–∏—Å—Ç–∏–ª –∏—Å—Ç–æ—Ä–∏—é (–±—ã–ª–æ ${historyLength} —Å–æ–æ–±—â–µ–Ω–∏–π)`);
  ctx.reply('Conversation history cleared!');
});

bot.on('text', async (ctx) => {
  const userId = ctx.from.id;
  const userMessage = ctx.message.text;
  const username = ctx.from.username || 'unknown';

  log(`üí¨ –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç ${userId} (@${username}): "${userMessage.substring(0, 50)}${userMessage.length > 50 ? '...' : ''}"`);

  // Get or initialize conversation history
  if (!conversations.has(userId)) {
    conversations.set(userId, []);
    log(`üìù –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∏—Å—Ç–æ—Ä–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ${userId}`);
  }
  const history = conversations.get(userId);

  // Add user message to history
  history.push({ role: 'user', content: userMessage });
  log(`üìä –ò—Å—Ç–æ—Ä–∏—è: ${history.length} —Å–æ–æ–±—â–µ–Ω–∏–π`);

  try {
    // Show typing indicator
    await ctx.sendChatAction('typing');

    // Send to both OpenAI and Ollama in parallel
    log('üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI –∏ Ollama...');
    const startTime = Date.now();
    
    const [openaiResponse, ollamaResponse] = await Promise.allSettled([
      getOpenAIResponse(history),
      getOllamaResponse(history),
    ]);

    const totalDuration = Date.now() - startTime;
    log(`‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: ${totalDuration}ms`);

    // Handle OpenAI response
    if (openaiResponse.status === 'fulfilled') {
      log(`‚úâÔ∏è  –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ OpenAI –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ${userId}`);
      await ctx.reply(`ü§ñ OpenAI (gpt-4o-mini):\n\n${openaiResponse.value}`);
    } else {
      log(`‚ùå –û—à–∏–±–∫–∞ OpenAI –¥–ª—è ${userId}:`, openaiResponse.reason.message);
      await ctx.reply('‚ùå OpenAI: Error getting response');
    }

    // Handle Ollama response
    if (ollamaResponse.status === 'fulfilled') {
      log(`‚úâÔ∏è  –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ Ollama –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ${userId}`);
      await ctx.reply(`ü¶ô Ollama (llama3.2:3b):\n\n${ollamaResponse.value}`);
    } else {
      log(`‚ùå –û—à–∏–±–∫–∞ Ollama –¥–ª—è ${userId}:`, ollamaResponse.reason.message);
      await ctx.reply('‚ùå Ollama: Error getting response (is Ollama running?)');
    }

    // Add assistant response to history (using OpenAI's response if available)
    if (openaiResponse.status === 'fulfilled') {
      history.push({ role: 'assistant', content: openaiResponse.value });
    }

    // Keep only last 20 messages to avoid token limits
    if (history.length > 20) {
      const removed = history.length - 20;
      history.splice(0, removed);
      log(`üßπ –û—á–∏—â–µ–Ω–æ ${removed} —Å—Ç–∞—Ä—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏`);
    }
    
    log(`‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è ${userId}`);
  } catch (error) {
    log(`üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è ${userId}:`, error.message);
    console.error('Error:', error);
    ctx.reply('Sorry, something went wrong. Please try again.');
  }
});

bot.launch();

log('üöÄ –ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ');
log('üì° –û–∂–∏–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...');

// Enable graceful stop
process.once('SIGINT', () => {
  log('‚ö†Ô∏è  –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª SIGINT, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–æ—Ç–∞...');
  bot.stop('SIGINT');
});
process.once('SIGTERM', () => {
  log('‚ö†Ô∏è  –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª SIGTERM, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–æ—Ç–∞...');
  bot.stop('SIGTERM');
});

